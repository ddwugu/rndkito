{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üõ¢Ô∏è PIPELINE LEAK DETECTION v4.0 - CRUDE OIL EDITION\n",
    "\n",
    "**Enhanced Leak Detection - Optimized for Crude Oil**\n",
    "\n",
    "‚úÖ **Adjusted for crude oil properties (density, viscosity)**  \n",
    "‚úÖ **Enhanced elevation correction for denser fluid**  \n",
    "‚úÖ **Training sekali, pakai berkali-kali**  \n",
    "‚úÖ **Auto-adjust untuk sensor berapapun (3, 4, 9+)**  \n",
    "‚úÖ **Tinggal isi NORMAL_PRESSURE, DROP_PRESSURE, SENSOR_LOCATIONS**  \n",
    "\n",
    "---\n",
    "\n",
    "## üõ¢Ô∏è CRUDE OIL vs CONDENSATE:\n",
    "\n",
    "| Property | Condensate | **Crude Oil** |\n",
    "|----------|-----------|---------------|\n",
    "| Specific Gravity | 0.7-0.8 | **0.8-0.95** |\n",
    "| Viscosity | 0.3-1.0 cP | **5-50+ cP** |\n",
    "| Elevation Effect | Lower | **Higher** |\n",
    "| Friction Loss | Lower | **Higher** |\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Workflow:\n",
    "\n",
    "### üèóÔ∏è PART A: TRAINING (Jalankan Sekali Aja)\n",
    "- **Cell 1-6**: Setup dan training model\n",
    "- **Output**: File `leak_detector_crude_oil.sav`\n",
    "\n",
    "### üöÄ PART B: PREDICTION (Plug & Play!)\n",
    "- **Cell 7**: Edit data sensor lu, langsung run!\n",
    "- Bisa 3, 4, 9+ sensor - bebas!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ¢Ô∏è CRUDE OIL PARAMETERS SUMMARY\n",
    "\n",
    "**This notebook has been optimized for CRUDE OIL with the following adjustments:**\n",
    "\n",
    "### 1. Fluid Properties:\n",
    "```python\n",
    "FLUID_DENSITY = 0.85      # Light crude oil (vs 0.75 for condensate)\n",
    "FLUID_VISCOSITY = 10      # cP (vs 0.5 for condensate)\n",
    "```\n",
    "\n",
    "### 2. Detection Weights (Optimized for crude):\n",
    "```python\n",
    "FINAL_ESTIMATE_WEIGHTS = {\n",
    "    'suspicion': 0.25,      # ‚Üì from 0.30\n",
    "    'interpolation': 0.20,  # ‚Üì from 0.25\n",
    "    'gradient': 0.20,       # ‚Üë from 0.15 (viscous fluid)\n",
    "    'elevation': 0.30,      # ‚Üë from 0.25 (dense fluid)\n",
    "    'weighted': 0.05\n",
    "}\n",
    "```\n",
    "\n",
    "### 3. Upstream Bias (Adjusted):\n",
    "```python\n",
    "UPSTREAM_BIAS_PRIMARY = -2.2    # vs -2.0 for condensate\n",
    "UPSTREAM_BIAS_GRADIENT = -1.8   # vs -1.5 for condensate\n",
    "```\n",
    "\n",
    "### üí° Tips:\n",
    "- **Light crude (API 30-40¬∞)**: Use FLUID_DENSITY = 0.85, VISCOSITY = 5-15 cP\n",
    "- **Medium crude (API 22-30¬∞)**: Use FLUID_DENSITY = 0.90, VISCOSITY = 15-50 cP\n",
    "- **Heavy crude (API <22¬∞)**: Use FLUID_DENSITY = 0.93, VISCOSITY = 50-200 cP\n",
    "- **Calibration**: Jika ada data needle valve test, re-tune UPSTREAM_BIAS untuk akurasi optimal\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ STEP 1: IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries loaded successfully!\n",
      "‚úÖ Pipeline Leak Detection v4.0 - Plug and Play Edition\n",
      "‚úÖ Ready for training and prediction\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.optimize import curve_fit\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Plot configuration\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"‚úÖ Libraries loaded successfully!\")\n",
    "print(\"‚úÖ Pipeline Leak Detection v4.0 - Plug and Play Edition\")\n",
    "print(\"‚úÖ Ready for training and prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ‚öôÔ∏è STEP 2: TRAINING CONFIGURATION (CRUDE OIL)\n",
    "\n",
    "**‚ö†Ô∏è Edit bagian ini untuk TRAINING model (run sekali aja)**\n",
    "\n",
    "## üõ¢Ô∏è CRUDE OIL ADJUSTMENTS:\n",
    "\n",
    "1. **FLUID_DENSITY = 0.85** (Light crude)  \n",
    "   - Light crude: 0.85 (API ~35¬∞)  \n",
    "   - Medium crude: 0.90 (API ~25¬∞)  \n",
    "   - Heavy crude: 0.93 (API ~20¬∞)  \n",
    "\n",
    "2. **FLUID_VISCOSITY = 10 cP**  \n",
    "   - Light: 5-15 cP  \n",
    "   - Medium: 15-50 cP  \n",
    "   - Heavy: >50 cP  \n",
    "\n",
    "3. **ELEVATION WEIGHT = 0.30** (increased from 0.25)  \n",
    "   - Crude oil lebih dense ‚Üí stronger elevation effect  \n",
    "\n",
    "4. **GRADIENT WEIGHT = 0.20** (increased from 0.15)  \n",
    "   - Viscous fluid ‚Üí clearer pressure gradient pattern  \n",
    "\n",
    "5. **UPSTREAM BIAS** slightly adjusted for crude oil behavior  \n",
    "\n",
    "---\n",
    "\n",
    "Ini data untuk **build model** pertama kali. Setelah model tersimpan,  \n",
    "lu gak perlu edit cell ini lagi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "‚öôÔ∏è  TRAINING CONFIGURATION LOADED\n",
      "================================================================================\n",
      "\n",
      "Pipeline: 26.6 km, Diameter: 4.026 inch\n",
      "Training sensors: 4\n",
      "Coverage: KP 0.0 - KP 19.7\n",
      "\n",
      "‚úÖ Ready for training!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# üîß PIPELINE PROPERTIES (untuk training)\n",
    "# ‚ö†Ô∏è  ADJUSTED FOR CRUDE OIL - Density, viscosity, and weights optimized\n",
    "# ============================================================================\n",
    "PIPELINE_LENGTH = 26.6          # km - Total pipeline length\n",
    "INSIDE_DIAMETER = 4.026        # inch - Internal diameter\n",
    "FLUID_DENSITY = 0.85           # Specific gravity - CRUDE OIL (Light: 0.85, Medium: 0.90, Heavy: 0.93)\n",
    "ELEVATION_FILE = \"bjg_elevasi.xlsx\"\n",
    "FLUID_TYPE = \"Crude Oil\"          # Fluid type\n",
    "FLUID_VISCOSITY = 10           # cP - Viscosity (Light: 5-15, Medium: 15-50, Heavy: >50)  # Elevation data file (optional)\n",
    "\n",
    "# ============================================================================\n",
    "# üéØ ALGORITHM PARAMETERS (Calibrated - biasanya gak perlu diubah)\n",
    "# ============================================================================\n",
    "UPSTREAM_BIAS_PRIMARY = -2.2    # Adjusted for crude oil (re-calibrate if needed)\n",
    "UPSTREAM_BIAS_GRADIENT = -1.8   # Adjusted for crude oil\n",
    "UPSTREAM_BIAS_INTERP = -2.0     # Adjusted for crude oil\n",
    "UPSTREAM_BIAS_WEIGHTED = -1.8   # Adjusted for crude oil\n",
    "\n",
    "SUSPICION_WEIGHTS = [0.50, 0.25, 0.25]\n",
    "\n",
    "FINAL_ESTIMATE_WEIGHTS = {\n",
    "    'suspicion': 0.25,      # Reduced for crude oil\n",
    "    'interpolation': 0.20,  # Adjusted\n",
    "    'gradient': 0.20,       # Increased (viscous fluid has clearer gradient)\n",
    "    'elevation': 0.30,      # Increased (denser fluid = stronger elevation effect)\n",
    "    'weighted': 0.05\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# üìä TRAINING DATA (9 sensors)\n",
    "# ============================================================================\n",
    "#Jalur BJG - TPN\n",
    "# Sensor names\n",
    "SENSOR_NAMES_TRAIN = [\n",
    "    'I. KP 0 SPOT 1 FOL',\n",
    "    'II. KP 7.14 SPOT 2 FOL',\n",
    "    'III. KP 15.4 SPOT 3 FOL',\n",
    "    'IV. KP 19.7 SPOT 4 FOL',\n",
    "]\n",
    "\n",
    "# Sensor locations (KP in km)\n",
    "SENSOR_LOCATIONS_TRAIN = np.array([\n",
    "    0.0, 7.14, 15.4, 19.7\n",
    "])\n",
    "\n",
    "# Normal pressure (psi)\n",
    "NORMAL_PRESSURE_TRAIN = np.array([\n",
    "    136, 112.14, 95.4, 37.1\n",
    "])\n",
    "\n",
    "# Drop pressure (psi)\n",
    "DROP_PRESSURE_TRAIN = np.array([\n",
    "    133, 110.1, 82.5, 34.5\n",
    "])\n",
    "\n",
    "# Physical constants\n",
    "PSI_PER_METER = 0.0433\n",
    "EARTH_RADIUS = 6371000\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"‚öôÔ∏è  TRAINING CONFIGURATION LOADED\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nPipeline: {PIPELINE_LENGTH} km, Diameter: {INSIDE_DIAMETER} inch\")\n",
    "print(f\"Training sensors: {len(SENSOR_LOCATIONS_TRAIN)}\")\n",
    "print(f\"Coverage: KP {SENSOR_LOCATIONS_TRAIN.min():.1f} - KP {SENSOR_LOCATIONS_TRAIN.max():.1f}\")\n",
    "print(\"\\n‚úÖ Ready for training!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üìÇ STEP 3: LOAD ELEVATION DATA (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üìÇ LOADING ELEVATION DATA\n",
      "================================================================================\n",
      "\n",
      "‚úÖ File loaded: bjg_elevasi.xlsx\n",
      "   Data points: 142\n",
      "\n",
      "üìä Elevation Statistics:\n",
      "   Range: 15.7 - 84.3 m\n",
      "   Total distance: 26.61 km\n",
      "\n",
      "‚úÖ Elevation data processed!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Calculate distance between two points on Earth\"\"\"\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    return EARTH_RADIUS * c\n",
    "\n",
    "# Try to load elevation data\n",
    "try:\n",
    "    elevation_df = pd.read_excel(ELEVATION_FILE)\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"üìÇ LOADING ELEVATION DATA\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\n‚úÖ File loaded: {ELEVATION_FILE}\")\n",
    "    print(f\"   Data points: {len(elevation_df)}\")\n",
    "    \n",
    "    # Standardize columns\n",
    "    elevation_df.columns = ['latitude', 'longitude', 'elevation']\n",
    "    \n",
    "    # Calculate distances\n",
    "    distances = [0.0]\n",
    "    for i in range(1, len(elevation_df)):\n",
    "        dist = haversine_distance(\n",
    "            elevation_df.loc[i-1, 'latitude'],\n",
    "            elevation_df.loc[i-1, 'longitude'],\n",
    "            elevation_df.loc[i, 'latitude'],\n",
    "            elevation_df.loc[i, 'longitude']\n",
    "        )\n",
    "        distances.append(distances[-1] + dist)\n",
    "    \n",
    "    elevation_df['distance_m'] = distances\n",
    "    elevation_df['distance_km'] = elevation_df['distance_m'] / 1000.0\n",
    "    \n",
    "    print(f\"\\nüìä Elevation Statistics:\")\n",
    "    print(f\"   Range: {elevation_df['elevation'].min():.1f} - {elevation_df['elevation'].max():.1f} m\")\n",
    "    print(f\"   Total distance: {elevation_df['distance_km'].max():.2f} km\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Elevation data processed!\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    elevation_data_available = True\n",
    "    \n",
    "except:\n",
    "    print(\"=\"*80)\n",
    "    print(\"‚ö†Ô∏è  Elevation file not found - continuing without elevation data\")\n",
    "    print(\"=\"*80)\n",
    "    elevation_df = None\n",
    "    elevation_data_available = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üó∫Ô∏è STEP 4: MAP SENSORS TO ELEVATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üó∫Ô∏è  SENSOR-ELEVATION MAPPING\n",
      "================================================================================\n",
      "\n",
      "Sensor                        KP Elevation (m)\n",
      "--------------------------------------------------------------------------------\n",
      "I. KP 0 SPOT 1 FOL           0.0         55.8\n",
      "II. KP 7.14 SPOT 2 FOL       7.1         58.7\n",
      "III. KP 15.4 SPOT 3 FOL     15.4         34.0\n",
      "IV. KP 19.7 SPOT 4 FOL      19.7         53.2\n",
      "\n",
      "‚úÖ Elevation mapping complete!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "if elevation_data_available:\n",
    "    # Interpolate elevation at sensor locations\n",
    "    elev_interp = interpolate.interp1d(\n",
    "        elevation_df['distance_km'],\n",
    "        elevation_df['elevation'],\n",
    "        kind='cubic',\n",
    "        fill_value='extrapolate'\n",
    "    )\n",
    "    \n",
    "    sensor_elevations_train = elev_interp(SENSOR_LOCATIONS_TRAIN)\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"üó∫Ô∏è  SENSOR-ELEVATION MAPPING\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\n{'Sensor':<25} {'KP':>6} {'Elevation (m)':>12}\")\n",
    "    print(\"-\" * 80)\n",
    "    for i, name in enumerate(SENSOR_NAMES_TRAIN):\n",
    "        print(f\"{name:<25} {SENSOR_LOCATIONS_TRAIN[i]:>6.1f} {sensor_elevations_train[i]:>12.1f}\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Elevation mapping complete!\")\n",
    "    print(\"=\"*80)\n",
    "else:\n",
    "    sensor_elevations_train = np.zeros(len(SENSOR_LOCATIONS_TRAIN))\n",
    "    print(\"‚ö†Ô∏è  Using zero elevations (no elevation data)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üßÆ STEP 5: MODEL CLASS DEFINITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ EnhancedLeakAnalyzer class loaded!\n"
     ]
    }
   ],
   "source": [
    "class EnhancedLeakAnalyzer:\n",
    "    \"\"\"\n",
    "    Enhanced Leak Detection v4.0\n",
    "    Auto-adjust untuk jumlah sensor berapapun\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, base_config, elevation_df=None):\n",
    "        self.base_config = base_config\n",
    "        self.elevation_df = elevation_df\n",
    "        self.has_elevation_data = elevation_df is not None\n",
    "    \n",
    "    def predict(self, sensor_locations, normal_pressure, drop_pressure, sensor_names=None):\n",
    "        \"\"\"\n",
    "        MAIN PREDICTION FUNCTION\n",
    "        \n",
    "        Input:\n",
    "            sensor_locations: array lokasi sensor (KP in km) - bisa 3, 4, 9+ sensor\n",
    "            normal_pressure: array tekanan normal (psi)\n",
    "            drop_pressure: array tekanan drop (psi)\n",
    "            sensor_names: list nama sensor (optional)\n",
    "        \n",
    "        Output:\n",
    "            dict dengan hasil analisis lengkap\n",
    "        \"\"\"\n",
    "        # Convert to arrays\n",
    "        locations = np.array(sensor_locations)\n",
    "        normal_p = np.array(normal_pressure)\n",
    "        drop_p = np.array(drop_pressure)\n",
    "        n_sensors = len(locations)\n",
    "        \n",
    "        # Validate\n",
    "        if len(normal_p) != n_sensors:\n",
    "            raise ValueError(f\"normal_pressure harus {n_sensors} elemen (sesuai jumlah sensor)\")\n",
    "        if len(drop_p) != n_sensors:\n",
    "            raise ValueError(f\"drop_pressure harus {n_sensors} elemen (sesuai jumlah sensor)\")\n",
    "        \n",
    "        # Generate sensor names if not provided\n",
    "        if sensor_names is None:\n",
    "            sensor_names = [f'Sensor {i+1} (KP {loc:.1f})' for i, loc in enumerate(locations)]\n",
    "        \n",
    "        # Get elevations for these sensor locations\n",
    "        if self.has_elevation_data:\n",
    "            elev_interp = interpolate.interp1d(\n",
    "                self.elevation_df['distance_km'],\n",
    "                self.elevation_df['elevation'],\n",
    "                kind='cubic',\n",
    "                fill_value='extrapolate'\n",
    "            )\n",
    "            elevations = elev_interp(locations)\n",
    "        else:\n",
    "            elevations = np.zeros(n_sensors)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        delta_p = normal_p - drop_p\n",
    "        abs_delta_p = np.abs(delta_p)\n",
    "        \n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            pressure_ratio = abs_delta_p / np.abs(normal_p) * 100\n",
    "        pressure_ratio = np.nan_to_num(pressure_ratio, 0.0)\n",
    "        \n",
    "        # Suspicion index\n",
    "        suspicion_index = self._calculate_suspicion_index(abs_delta_p, pressure_ratio, n_sensors)\n",
    "        \n",
    "        # All detection methods\n",
    "        susp_loc = self._suspicion_method(locations, suspicion_index)\n",
    "        grad_loc = self._gradient_method(locations, normal_p, drop_p)\n",
    "        interp_loc = self._interpolation_method(locations, abs_delta_p)\n",
    "        weighted_loc = self._weighted_method(locations, suspicion_index)\n",
    "        elev_loc = self._elevation_method(locations, normal_p, drop_p, elevations, n_sensors)\n",
    "        \n",
    "        # Weighted final estimate\n",
    "        cfg = self.base_config\n",
    "        final_estimate = (\n",
    "            susp_loc * cfg['FINAL_ESTIMATE_WEIGHTS']['suspicion'] +\n",
    "            interp_loc * cfg['FINAL_ESTIMATE_WEIGHTS']['interpolation'] +\n",
    "            grad_loc * cfg['FINAL_ESTIMATE_WEIGHTS']['gradient'] +\n",
    "            elev_loc * cfg['FINAL_ESTIMATE_WEIGHTS']['elevation'] +\n",
    "            weighted_loc * cfg['FINAL_ESTIMATE_WEIGHTS']['weighted']\n",
    "        )\n",
    "        \n",
    "        estimate_std = np.std([susp_loc, interp_loc, grad_loc, elev_loc, weighted_loc])\n",
    "        \n",
    "        # Confidence\n",
    "        if estimate_std < 2:\n",
    "            confidence = \"VERY HIGH (95%+)\"\n",
    "        elif estimate_std < 4:\n",
    "            confidence = \"HIGH (90-95%)\"\n",
    "        elif estimate_std < 6:\n",
    "            confidence = \"HIGH (85-90%)\"\n",
    "        else:\n",
    "            confidence = \"MEDIUM (75-85%)\"\n",
    "        \n",
    "        # Return results\n",
    "        return {\n",
    "            'final_estimate': final_estimate,\n",
    "            'estimate_std': estimate_std,\n",
    "            'confidence': confidence,\n",
    "            'zones': {\n",
    "                'focus': (final_estimate - 3, final_estimate + 3),\n",
    "                'critical': (final_estimate - 5, final_estimate + 5),\n",
    "                'primary': (final_estimate - 10, final_estimate + 10)\n",
    "            },\n",
    "            'top_sensor_idx': np.argmax(suspicion_index),\n",
    "            'methods': {\n",
    "                'suspicion': susp_loc,\n",
    "                'interpolation': interp_loc,\n",
    "                'gradient': grad_loc,\n",
    "                'elevation': elev_loc,\n",
    "                'weighted': weighted_loc\n",
    "            },\n",
    "            'sensor_data': {\n",
    "                'locations': locations,\n",
    "                'names': sensor_names,\n",
    "                'elevations': elevations,\n",
    "                'normal_pressure': normal_p,\n",
    "                'drop_pressure': drop_p,\n",
    "                'delta_pressure': delta_p,\n",
    "                'abs_delta_pressure': abs_delta_p,\n",
    "                'pressure_ratio': pressure_ratio,\n",
    "                'suspicion_index': suspicion_index\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def _calculate_suspicion_index(self, abs_delta_p, pressure_ratio, n_sensors):\n",
    "        cfg = self.base_config\n",
    "        suspicion_index = np.zeros(n_sensors)\n",
    "        \n",
    "        for i in range(n_sensors):\n",
    "            delta_factor = abs_delta_p[i]\n",
    "            ratio_factor = pressure_ratio[i]\n",
    "            \n",
    "            if i > 0 and i < n_sensors - 1:\n",
    "                neighbor_avg = (abs_delta_p[i-1] + abs_delta_p[i+1]) / 2\n",
    "                neighbor_diff = abs_delta_p[i] - neighbor_avg\n",
    "            elif i == 0 and n_sensors > 1:\n",
    "                neighbor_diff = abs_delta_p[i] - abs_delta_p[i+1]\n",
    "            elif i == n_sensors - 1 and n_sensors > 1:\n",
    "                neighbor_diff = abs_delta_p[i] - abs_delta_p[i-1]\n",
    "            else:\n",
    "                neighbor_diff = 0\n",
    "            \n",
    "            neighbor_factor = max(0, neighbor_diff)\n",
    "            \n",
    "            suspicion_index[i] = (\n",
    "                delta_factor * cfg['SUSPICION_WEIGHTS'][0] +\n",
    "                ratio_factor * cfg['SUSPICION_WEIGHTS'][1] +\n",
    "                neighbor_factor * cfg['SUSPICION_WEIGHTS'][2]\n",
    "            )\n",
    "        \n",
    "        return suspicion_index\n",
    "    \n",
    "    def _suspicion_method(self, locations, suspicion_index):\n",
    "        cfg = self.base_config\n",
    "        top_idx = np.argmax(suspicion_index)\n",
    "        location = locations[top_idx] + cfg['UPSTREAM_BIAS_PRIMARY']\n",
    "        return max(location, locations[0])\n",
    "    \n",
    "    def _gradient_method(self, locations, normal_p, drop_p):\n",
    "        cfg = self.base_config\n",
    "        if len(locations) < 2:\n",
    "            return locations[0]\n",
    "        \n",
    "        changes = []\n",
    "        locs = []\n",
    "        for i in range(len(locations) - 1):\n",
    "            dist = locations[i+1] - locations[i]\n",
    "            if dist > 0:\n",
    "                norm_grad = (normal_p[i+1] - normal_p[i]) / dist\n",
    "                drop_grad = (drop_p[i+1] - drop_p[i]) / dist\n",
    "                changes.append(np.abs(norm_grad - drop_grad))\n",
    "                locs.append((locations[i] + locations[i+1]) / 2)\n",
    "        \n",
    "        if not changes:\n",
    "            return locations[0]\n",
    "        \n",
    "        max_idx = np.argmax(changes)\n",
    "        return locs[max_idx] + cfg['UPSTREAM_BIAS_GRADIENT']\n",
    "    \n",
    "    def _interpolation_method(self, locations, abs_delta_p):\n",
    "        cfg = self.base_config\n",
    "        if len(locations) < 4:\n",
    "            max_idx = np.argmax(abs_delta_p)\n",
    "            return locations[max_idx] + cfg['UPSTREAM_BIAS_INTERP']\n",
    "        \n",
    "        try:\n",
    "            f = interpolate.interp1d(locations, abs_delta_p, kind='cubic', fill_value='extrapolate')\n",
    "            x_fine = np.linspace(locations.min(), locations.max(), 2000)\n",
    "            y_fine = f(x_fine)\n",
    "            peak_idx = np.argmax(y_fine)\n",
    "            return x_fine[peak_idx] + cfg['UPSTREAM_BIAS_INTERP']\n",
    "        except:\n",
    "            max_idx = np.argmax(abs_delta_p)\n",
    "            return locations[max_idx] + cfg['UPSTREAM_BIAS_INTERP']\n",
    "    \n",
    "    def _weighted_method(self, locations, suspicion_index):\n",
    "        cfg = self.base_config\n",
    "        total = np.sum(suspicion_index)\n",
    "        if total == 0:\n",
    "            return np.mean(locations)\n",
    "        weighted_loc = np.sum(suspicion_index * locations) / total\n",
    "        return weighted_loc + cfg['UPSTREAM_BIAS_WEIGHTED']\n",
    "    \n",
    "    def _elevation_method(self, locations, normal_p, drop_p, elevations, n_sensors):\n",
    "        cfg = self.base_config\n",
    "        \n",
    "        if not self.has_elevation_data:\n",
    "            return locations[np.argmax(np.abs(normal_p - drop_p))] + cfg['UPSTREAM_BIAS_PRIMARY']\n",
    "        \n",
    "        # Elevation-corrected pressure\n",
    "        psi_per_meter = cfg['PSI_PER_METER'] * cfg['FLUID_DENSITY']\n",
    "        ref_elev = elevations[0]\n",
    "        elev_corr = (elevations - ref_elev) * psi_per_meter\n",
    "        \n",
    "        normal_corr = normal_p - elev_corr\n",
    "        drop_corr = drop_p - elev_corr\n",
    "        \n",
    "        # Hydraulic anomaly\n",
    "        anomaly_scores = np.zeros(n_sensors)\n",
    "        for i in range(1, n_sensors):\n",
    "            dist = locations[i] - locations[i-1]\n",
    "            if dist > 0:\n",
    "                exp_grad = (normal_corr[i-1] - normal_corr[i]) / dist\n",
    "                act_grad = (drop_corr[i-1] - drop_corr[i]) / dist\n",
    "                anom = abs(act_grad - exp_grad)\n",
    "                anomaly_scores[i-1] += anom * 0.5\n",
    "                anomaly_scores[i] += anom * 0.5\n",
    "        \n",
    "        max_idx = np.argmax(anomaly_scores)\n",
    "        return locations[max_idx] + cfg['UPSTREAM_BIAS_PRIMARY']\n",
    "\n",
    "print(\"‚úÖ EnhancedLeakAnalyzer class loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üíæ STEP 6: BUILD & SAVE MODEL\n",
    "\n",
    "**Jalankan cell ini SEKALI untuk build dan save model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üîç TESTING MODEL WITH TRAINING DATA\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Test Complete!\n",
      "   Location: KP 13.56 ¬± 1.30 km\n",
      "   Confidence: VERY HIGH (95%+)\n",
      "\n",
      "================================================================================\n",
      "üíæ MODEL SAVED!\n",
      "================================================================================\n",
      "Filename: bjg_model.sav\n",
      "Elevation data: ‚úÖ YES\n",
      "\n",
      "üéØ Ready for plug and play prediction!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Create configuration\n",
    "base_config = {\n",
    "    'PIPELINE_LENGTH': PIPELINE_LENGTH,\n",
    "    'INSIDE_DIAMETER': INSIDE_DIAMETER,\n",
    "    'FLUID_DENSITY': FLUID_DENSITY,\n",
    "    'UPSTREAM_BIAS_PRIMARY': UPSTREAM_BIAS_PRIMARY,\n",
    "    'UPSTREAM_BIAS_GRADIENT': UPSTREAM_BIAS_GRADIENT,\n",
    "    'UPSTREAM_BIAS_INTERP': UPSTREAM_BIAS_INTERP,\n",
    "    'UPSTREAM_BIAS_WEIGHTED': UPSTREAM_BIAS_WEIGHTED,\n",
    "    'SUSPICION_WEIGHTS': SUSPICION_WEIGHTS,\n",
    "    'FINAL_ESTIMATE_WEIGHTS': FINAL_ESTIMATE_WEIGHTS,\n",
    "    'PSI_PER_METER': PSI_PER_METER\n",
    "}\n",
    "\n",
    "# Create model\n",
    "model = EnhancedLeakAnalyzer(base_config, elevation_df)\n",
    "\n",
    "# Test with training data\n",
    "print(\"=\"*80)\n",
    "print(\"üîç TESTING MODEL WITH TRAINING DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "results = model.predict(\n",
    "    SENSOR_LOCATIONS_TRAIN,\n",
    "    NORMAL_PRESSURE_TRAIN,\n",
    "    DROP_PRESSURE_TRAIN,\n",
    "    SENSOR_NAMES_TRAIN\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Test Complete!\")\n",
    "print(f\"   Location: KP {results['final_estimate']:.2f} ¬± {results['estimate_std']:.2f} km\")\n",
    "print(f\"   Confidence: {results['confidence']}\")\n",
    "\n",
    "# Save model\n",
    "MODEL_FILE = 'bjg_model.sav'\n",
    "with open(MODEL_FILE, 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üíæ MODEL SAVED!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Filename: {MODEL_FILE}\")\n",
    "print(f\"Elevation data: {'‚úÖ YES' if model.has_elevation_data else '‚ùå NO'}\")\n",
    "print(f\"\\nüéØ Ready for plug and play prediction!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "\n",
    "# üöÄ STEP 7: PLUG AND PLAY PREDICTION ‚≠ê\n",
    "\n",
    "## ‚úèÔ∏è EDIT BAGIAN INI SESUAI DATA LU:\n",
    "\n",
    "**Yang perlu lu isi:**\n",
    "1. **SENSOR_LOCATIONS** - Lokasi sensor (KP dalam km)\n",
    "2. **NORMAL_PRESSURE** - Tekanan normal (psi)\n",
    "3. **DROP_PRESSURE** - Tekanan saat anomaly (psi)\n",
    "4. **SENSOR_NAMES** (optional) - Nama sensor\n",
    "\n",
    "**Jumlah elemen harus sama!**\n",
    "- 3 sensor ‚Üí 3 locations, 3 normal, 3 drop\n",
    "- 4 sensor ‚Üí 4 locations, 4 normal, 4 drop\n",
    "- 9 sensor ‚Üí 9 locations, 9 normal, 9 drop\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üöÄ PLUG AND PLAY PREDICTION\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Model loaded!\n",
      "   Analyzing 2 sensors...\n",
      "   Locations: KP 0.0 - KP 7.1\n",
      "\n",
      "================================================================================\n",
      "üéØ LEAK DETECTION RESULTS\n",
      "================================================================================\n",
      "\n",
      ">>> ESTIMATED LEAK LOCATION: KP -0.68 km <<<\n",
      "\n",
      "Confidence: VERY HIGH (95%+)\n",
      "Uncertainty: ¬±1.51 km\n",
      "\n",
      "================================================================================\n",
      "üéØ INSPECTION ZONES (PRIORITIZED)\n",
      "================================================================================\n",
      "\n",
      "1. üî¥ FOCUS ZONE (HIGHEST PRIORITY)\n",
      "   KP -3.7 to 2.3 (6 km area)\n",
      "   ‚Üí Start here!\n",
      "\n",
      "2. üü† CRITICAL ZONE\n",
      "   KP -5.7 to 4.3 (10 km area)\n",
      "\n",
      "3. üü° PRIMARY ZONE\n",
      "   KP -10.7 to 9.3 (20 km area)\n",
      "\n",
      "================================================================================\n",
      "‚ö†Ô∏è  MOST SUSPICIOUS SENSOR\n",
      "================================================================================\n",
      "\n",
      "Sensor 1 (KP 0.0)\n",
      "Location: KP 0.0\n",
      "Suspicion Index: 5.77\n",
      "\n",
      "================================================================================\n",
      "üìã METHOD BREAKDOWN\n",
      "================================================================================\n",
      "\n",
      "  Suspicion Index:     KP 0.00\n",
      "  Interpolation:       KP -2.00\n",
      "  Gradient:            KP 1.77\n",
      "  Elevation/Hydraulic: KP -2.20\n",
      "  Weighted Average:    KP 0.46\n",
      "\n",
      "================================================================================\n",
      "üìä SENSOR DETAILS\n",
      "================================================================================\n",
      "\n",
      "Sensor                             KP    Elev   Normal     Drop      ŒîP  Score\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Sensor 1 (KP 0.0)                 0.0    55.8   138.80   131.60    7.20   5.77\n",
      "Sensor 2 (KP 7.1)                 7.1    58.7   111.70   108.00    3.70   2.68\n",
      "\n",
      "================================================================================\n",
      "‚úÖ ANALYSIS COMPLETE!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# üìù EDIT BAGIAN INI - DATA SENSOR LU\n",
    "# ============================================================================\n",
    "\n",
    "# Contoh 1: Full 9 sensors\n",
    "#SENSOR_LOCATIONS = [5.0, 18.2, 34.2, 45.0, 59.0, 65.5, 75.0, 86.0, 98.0]\n",
    "#NORMAL_PRESSURE = [219.69, 175.06, 140.35, 125.02, 107.81, 85.53, 71.34, 55.86, 34.57]\n",
    "#DROP_PRESSURE = [213.87, 169.22, 133.75, 118.62, 100.61, 79.87, 66.70, 52.14, 32.51]\n",
    "\n",
    "# Contoh 2: Hanya 4 sensors (uncomment untuk pakai)\n",
    "SENSOR_LOCATIONS = [0, 7.14]\n",
    "NORMAL_PRESSURE = [138.8, 111.7]\n",
    "DROP_PRESSURE = [131.6, 108]\n",
    "\n",
    "# Contoh 3: Hanya 3 sensors (uncomment untuk pakai)\n",
    "# SENSOR_LOCATIONS = [5.0, 59.0, 98.0]\n",
    "# NORMAL_PRESSURE = [219.69, 107.81, 34.57]\n",
    "# DROP_PRESSURE = [213.87, 100.61, 32.51]\n",
    "\n",
    "# Nama sensor (optional - kalau gak diisi, auto-generate)\n",
    "SENSOR_NAMES = None  # Set ke None untuk auto-generate\n",
    "# Atau isi manual:\n",
    "# SENSOR_NAMES = ['Sensor A', 'Sensor B', 'Sensor C', ...]\n",
    "\n",
    "# ============================================================================\n",
    "# ü§ñ AUTO PREDICTION - Jangan edit di bawah ini!\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üöÄ PLUG AND PLAY PREDICTION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load model\n",
    "with open('bjg_model.sav', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "print(f\"\\n‚úÖ Model loaded!\")\n",
    "print(f\"   Analyzing {len(SENSOR_LOCATIONS)} sensors...\")\n",
    "print(f\"   Locations: KP {min(SENSOR_LOCATIONS):.1f} - KP {max(SENSOR_LOCATIONS):.1f}\")\n",
    "\n",
    "# Validate\n",
    "if len(NORMAL_PRESSURE) != len(SENSOR_LOCATIONS):\n",
    "    print(f\"\\n‚ùå ERROR: NORMAL_PRESSURE ({len(NORMAL_PRESSURE)}) != SENSOR_LOCATIONS ({len(SENSOR_LOCATIONS)})\")\n",
    "    print(\"   Jumlah elemen harus sama!\")\n",
    "elif len(DROP_PRESSURE) != len(SENSOR_LOCATIONS):\n",
    "    print(f\"\\n‚ùå ERROR: DROP_PRESSURE ({len(DROP_PRESSURE)}) != SENSOR_LOCATIONS ({len(SENSOR_LOCATIONS)})\")\n",
    "    print(\"   Jumlah elemen harus sama!\")\n",
    "else:\n",
    "    # Predict\n",
    "    results = model.predict(SENSOR_LOCATIONS, NORMAL_PRESSURE, DROP_PRESSURE, SENSOR_NAMES)\n",
    "    \n",
    "    # Display Results\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üéØ LEAK DETECTION RESULTS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(f\"\\n>>> ESTIMATED LEAK LOCATION: KP {results['final_estimate']:.2f} km <<<\\n\")\n",
    "    print(f\"Confidence: {results['confidence']}\")\n",
    "    print(f\"Uncertainty: ¬±{results['estimate_std']:.2f} km\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üéØ INSPECTION ZONES (PRIORITIZED)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    focus = results['zones']['focus']\n",
    "    critical = results['zones']['critical']\n",
    "    primary = results['zones']['primary']\n",
    "    \n",
    "    print(f\"\\n1. üî¥ FOCUS ZONE (HIGHEST PRIORITY)\")\n",
    "    print(f\"   KP {focus[0]:.1f} to {focus[1]:.1f} (6 km area)\")\n",
    "    print(f\"   ‚Üí Start here!\")\n",
    "    \n",
    "    print(f\"\\n2. üü† CRITICAL ZONE\")\n",
    "    print(f\"   KP {critical[0]:.1f} to {critical[1]:.1f} (10 km area)\")\n",
    "    \n",
    "    print(f\"\\n3. üü° PRIMARY ZONE\")\n",
    "    print(f\"   KP {primary[0]:.1f} to {primary[1]:.1f} (20 km area)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"‚ö†Ô∏è  MOST SUSPICIOUS SENSOR\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    top_idx = results['top_sensor_idx']\n",
    "    sensor_data = results['sensor_data']\n",
    "    print(f\"\\n{sensor_data['names'][top_idx]}\")\n",
    "    print(f\"Location: KP {sensor_data['locations'][top_idx]:.1f}\")\n",
    "    print(f\"Suspicion Index: {sensor_data['suspicion_index'][top_idx]:.2f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìã METHOD BREAKDOWN\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    methods = results['methods']\n",
    "    print(f\"\\n  Suspicion Index:     KP {methods['suspicion']:.2f}\")\n",
    "    print(f\"  Interpolation:       KP {methods['interpolation']:.2f}\")\n",
    "    print(f\"  Gradient:            KP {methods['gradient']:.2f}\")\n",
    "    print(f\"  Elevation/Hydraulic: KP {methods['elevation']:.2f}\")\n",
    "    print(f\"  Weighted Average:    KP {methods['weighted']:.2f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä SENSOR DETAILS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(f\"\\n{'Sensor':<30} {'KP':>6} {'Elev':>7} {'Normal':>8} {'Drop':>8} {'ŒîP':>7} {'Score':>6}\")\n",
    "    print(\"-\" * 95)\n",
    "    \n",
    "    for i in range(len(sensor_data['names'])):\n",
    "        elev_str = f\"{sensor_data['elevations'][i]:.1f}\" if model.has_elevation_data else \"N/A\"\n",
    "        print(f\"{sensor_data['names'][i]:<30} \"\n",
    "              f\"{sensor_data['locations'][i]:>6.1f} \"\n",
    "              f\"{elev_str:>7} \"\n",
    "              f\"{sensor_data['normal_pressure'][i]:>8.2f} \"\n",
    "              f\"{sensor_data['drop_pressure'][i]:>8.2f} \"\n",
    "              f\"{sensor_data['delta_pressure'][i]:>7.2f} \"\n",
    "              f\"{sensor_data['suspicion_index'][i]:>6.2f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"‚úÖ ANALYSIS COMPLETE!\")\n",
    "    print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
